# ui.py
import streamlit as st
import pandas as pd
import time
from database import save_to_db, get_chat_history, get_db_count, clear_db
from llm import generate_response
from data import create_sample_evaluation_data
from metrics import get_metrics_descriptions

# --- ãƒãƒ£ãƒƒãƒˆãƒšãƒ¼ã‚¸ã®UI ---
def display_chat_page(pipe):
    """ãƒãƒ£ãƒƒãƒˆãƒšãƒ¼ã‚¸ã®UIã‚’è¡¨ç¤ºã™ã‚‹"""
    st.subheader("è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
    user_question = st.text_area("è³ªå•", key="question_input", height=100, value=st.session_state.get("current_question", ""))
    submit_button = st.button("è³ªå•ã‚’é€ä¿¡")

    # ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã®åˆæœŸåŒ–ï¼ˆå®‰å…¨ã®ãŸã‚ï¼‰
    if "current_question" not in st.session_state:
        st.session_state.current_question = ""
    if "current_answer" not in st.session_state:
        st.session_state.current_answer = ""
    if "response_time" not in st.session_state:
        st.session_state.response_time = 0.0
    if "feedback_given" not in st.session_state:
        st.session_state.feedback_given = False

    # è³ªå•ãŒé€ä¿¡ã•ã‚ŒãŸå ´åˆ
    if submit_button and user_question:
        st.session_state.current_question = user_question
        st.session_state.current_answer = "" # å›ç­”ã‚’ãƒªã‚»ãƒƒãƒˆ
        st.session_state.feedback_given = False # ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯çŠ¶æ…‹ã‚‚ãƒªã‚»ãƒƒãƒˆ

        with st.spinner("ãƒ¢ãƒ‡ãƒ«ãŒå›ç­”ã‚’ç”Ÿæˆä¸­..."):
            answer, response_time = generate_response(pipe, user_question)
            st.session_state.current_answer = answer
            st.session_state.response_time = response_time
            # ã“ã“ã§rerunã™ã‚‹ã¨å›ç­”ã¨ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ãŒä¸€åº¦ã«è¡¨ç¤ºã•ã‚Œã‚‹
            st.rerun()

    # å›ç­”ãŒè¡¨ç¤ºã•ã‚Œã‚‹ã¹ãã‹åˆ¤æ–­ (è³ªå•ãŒã‚ã‚Šã€å›ç­”ãŒç”Ÿæˆæ¸ˆã¿ã§ã€ã¾ã ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã•ã‚Œã¦ã„ãªã„)
    if st.session_state.current_question and st.session_state.current_answer:
        st.subheader("å›ç­”:")
        st.markdown(st.session_state.current_answer) # Markdownã§è¡¨ç¤º
        st.info(f"å¿œç­”æ™‚é–“: {st.session_state.response_time:.2f}ç§’")

        # ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ãƒ•ã‚©ãƒ¼ãƒ ã‚’è¡¨ç¤º (ã¾ã ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã•ã‚Œã¦ã„ãªã„å ´åˆ)
        if not st.session_state.feedback_given:
            display_feedback_form()
        else:
             # ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯é€ä¿¡æ¸ˆã¿ã®å ´åˆã€æ¬¡ã®è³ªå•ã‚’ä¿ƒã™ã‹ã€ãƒªã‚»ãƒƒãƒˆã™ã‚‹
             if st.button("æ¬¡ã®è³ªå•ã¸"):
                  # çŠ¶æ…‹ã‚’ãƒªã‚»ãƒƒãƒˆ
                  st.session_state.current_question = ""
                  st.session_state.current_answer = ""
                  st.session_state.response_time = 0.0
                  st.session_state.feedback_given = False
                  st.rerun() # ç”»é¢ã‚’ã‚¯ãƒªã‚¢


def display_feedback_form():
    """ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯å…¥åŠ›ãƒ•ã‚©ãƒ¼ãƒ ã‚’è¡¨ç¤ºã™ã‚‹"""
    with st.form("feedback_form"):
        st.subheader("ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯")
        feedback_options = ["æ­£ç¢º", "éƒ¨åˆ†çš„ã«æ­£ç¢º", "ä¸æ­£ç¢º"]
        # label_visibility='collapsed' ã§ãƒ©ãƒ™ãƒ«ã‚’éš ã™
        feedback = st.radio("å›ç­”ã®è©•ä¾¡", feedback_options, key="feedback_radio", label_visibility='collapsed', horizontal=True)
        correct_answer = st.text_area("ã‚ˆã‚Šæ­£ç¢ºãªå›ç­”ï¼ˆä»»æ„ï¼‰", key="correct_answer_input", height=100)
        feedback_comment = st.text_area("ã‚³ãƒ¡ãƒ³ãƒˆï¼ˆä»»æ„ï¼‰", key="feedback_comment_input", height=100)
        submitted = st.form_submit_button("ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’é€ä¿¡")
        if submitted:
            # ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ä¿å­˜
            is_correct = 1.0 if feedback == "æ­£ç¢º" else (0.5 if feedback == "éƒ¨åˆ†çš„ã«æ­£ç¢º" else 0.0)
            # ã‚³ãƒ¡ãƒ³ãƒˆãŒãªã„å ´åˆã§ã‚‚ 'æ­£ç¢º' ãªã©ã®è©•ä¾¡ã¯feedbackã«å«ã¾ã‚Œã‚‹ã‚ˆã†ã«ã™ã‚‹
            combined_feedback = f"{feedback}"
            if feedback_comment:
                combined_feedback += f": {feedback_comment}"

            save_to_db(
                st.session_state.current_question,
                st.session_state.current_answer,
                combined_feedback,
                correct_answer,
                is_correct,
                st.session_state.response_time
            )
            st.session_state.feedback_given = True
            st.success("ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ãŒä¿å­˜ã•ã‚Œã¾ã—ãŸï¼")
            # ãƒ•ã‚©ãƒ¼ãƒ é€ä¿¡å¾Œã«çŠ¶æ…‹ã‚’ãƒªã‚»ãƒƒãƒˆã—ãªã„æ–¹ãŒã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¯çµæœã‚’ç¢ºèªã—ã‚„ã™ã„ã‹ã‚‚
            # å¿…è¦ãªã‚‰ã“ã“ã§ãƒªã‚»ãƒƒãƒˆã—ã¦ st.rerun()
            st.rerun() # ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ãƒ•ã‚©ãƒ¼ãƒ ã‚’æ¶ˆã™ãŸã‚ã«å†å®Ÿè¡Œ

# --- å±¥æ­´é–²è¦§ãƒšãƒ¼ã‚¸ã®UI ---
def display_history_page():
    """å±¥æ­´é–²è¦§ãƒšãƒ¼ã‚¸ã®UIã‚’è¡¨ç¤ºã™ã‚‹"""
    st.subheader("ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã¨è©•ä¾¡æŒ‡æ¨™")
    history_df = get_chat_history()

    if history_df.empty:
        st.info("ã¾ã ãƒãƒ£ãƒƒãƒˆå±¥æ­´ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
        return

    # ã‚¿ãƒ–ã§ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’åˆ†ã‘ã‚‹
    tab1, tab2 = st.tabs(["å±¥æ­´é–²è¦§", "è©•ä¾¡æŒ‡æ¨™åˆ†æ"])

    with tab1:
        display_history_list(history_df)

    with tab2:
        display_metrics_analysis(history_df)

def display_history_list(history_df):
    """å±¥æ­´ãƒªã‚¹ãƒˆã‚’è¡¨ç¤ºã™ã‚‹"""
    st.write("#### å±¥æ­´ãƒªã‚¹ãƒˆ")
    # è¡¨ç¤ºã‚ªãƒ—ã‚·ãƒ§ãƒ³
    filter_options = {
        "ã™ã¹ã¦è¡¨ç¤º": None,
        "æ­£ç¢ºãªã‚‚ã®ã®ã¿": 1.0,
        "éƒ¨åˆ†çš„ã«æ­£ç¢ºãªã‚‚ã®ã®ã¿": 0.5,
        "ä¸æ­£ç¢ºãªã‚‚ã®ã®ã¿": 0.0
    }
    display_option = st.radio(
        "è¡¨ç¤ºãƒ•ã‚£ãƒ«ã‚¿",
        options=filter_options.keys(),
        horizontal=True,
        label_visibility="collapsed" # ãƒ©ãƒ™ãƒ«éè¡¨ç¤º
    )

    filter_value = filter_options[display_option]
    if filter_value is not None:
        # is_correctãŒNaNã®å ´åˆã‚’è€ƒæ…®
        filtered_df = history_df[history_df["is_correct"].notna() & (history_df["is_correct"] == filter_value)]
    else:
        filtered_df = history_df

    if filtered_df.empty:
        st.info("é¸æŠã—ãŸæ¡ä»¶ã«ä¸€è‡´ã™ã‚‹å±¥æ­´ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚")
        return

    # ãƒšãƒ¼ã‚¸ãƒãƒ¼ã‚·ãƒ§ãƒ³
    items_per_page = 5
    total_items = len(filtered_df)
    total_pages = (total_items + items_per_page - 1) // items_per_page
    current_page = st.number_input('ãƒšãƒ¼ã‚¸', min_value=1, max_value=total_pages, value=1, step=1)

    start_idx = (current_page - 1) * items_per_page
    end_idx = start_idx + items_per_page
    paginated_df = filtered_df.iloc[start_idx:end_idx]


    for i, row in paginated_df.iterrows():
        with st.expander(f"{row['timestamp']} - Q: {row['question'][:50] if row['question'] else 'N/A'}..."):
            st.markdown(f"**Q:** {row['question']}")
            st.markdown(f"**A:** {row['answer']}")
            st.markdown(f"**Feedback:** {row['feedback']}")
            if row['correct_answer']:
                st.markdown(f"**Correct A:** {row['correct_answer']}")

            # è©•ä¾¡æŒ‡æ¨™ã®è¡¨ç¤º
            st.markdown("---")
            cols = st.columns(3)
            cols[0].metric("æ­£ç¢ºæ€§ã‚¹ã‚³ã‚¢", f"{row['is_correct']:.1f}")
            cols[1].metric("å¿œç­”æ™‚é–“(ç§’)", f"{row['response_time']:.2f}")
            cols[2].metric("å˜èªæ•°", f"{row['word_count']}")

            cols = st.columns(3)
            # NaNã®å ´åˆã¯ãƒã‚¤ãƒ•ãƒ³è¡¨ç¤º
            cols[0].metric("BLEU", f"{row['bleu_score']:.4f}" if pd.notna(row['bleu_score']) else "-")
            cols[1].metric("é¡ä¼¼åº¦", f"{row['similarity_score']:.4f}" if pd.notna(row['similarity_score']) else "-")
            cols[2].metric("é–¢é€£æ€§", f"{row['relevance_score']:.4f}" if pd.notna(row['relevance_score']) else "-")

    st.caption(f"{total_items} ä»¶ä¸­ {start_idx+1} - {min(end_idx, total_items)} ä»¶ã‚’è¡¨ç¤º")


def display_metrics_analysis(history_df):
    """è©•ä¾¡æŒ‡æ¨™ã®åˆ†æçµæœã‚’è¡¨ç¤ºã™ã‚‹"""
    st.write("#### è©•ä¾¡æŒ‡æ¨™ã®åˆ†æ")

    # is_correct ãŒ NaN ã®ãƒ¬ã‚³ãƒ¼ãƒ‰ã‚’é™¤å¤–ã—ã¦åˆ†æ
    analysis_df = history_df.dropna(subset=['is_correct'])
    if analysis_df.empty:
        st.warning("åˆ†æå¯èƒ½ãªè©•ä¾¡ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
        return

    accuracy_labels = {1.0: 'æ­£ç¢º', 0.5: 'éƒ¨åˆ†çš„ã«æ­£ç¢º', 0.0: 'ä¸æ­£ç¢º'}
    analysis_df['æ­£ç¢ºæ€§'] = analysis_df['is_correct'].map(accuracy_labels)

    # æ­£ç¢ºæ€§ã®åˆ†å¸ƒ
    st.write("##### æ­£ç¢ºæ€§ã®åˆ†å¸ƒ")
    accuracy_counts = analysis_df['æ­£ç¢ºæ€§'].value_counts()
    if not accuracy_counts.empty:
        st.bar_chart(accuracy_counts)
    else:
        st.info("æ­£ç¢ºæ€§ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")

    # å¿œç­”æ™‚é–“ã¨ä»–ã®æŒ‡æ¨™ã®é–¢ä¿‚
    st.write("##### å¿œç­”æ™‚é–“ã¨ãã®ä»–ã®æŒ‡æ¨™ã®é–¢ä¿‚")
    metric_options = ["bleu_score", "similarity_score", "relevance_score", "word_count"]
    # åˆ©ç”¨å¯èƒ½ãªæŒ‡æ¨™ã®ã¿é¸æŠè‚¢ã«å«ã‚ã‚‹
    valid_metric_options = [m for m in metric_options if m in analysis_df.columns and analysis_df[m].notna().any()]

    if valid_metric_options:
        metric_option = st.selectbox(
            "æ¯”è¼ƒã™ã‚‹è©•ä¾¡æŒ‡æ¨™ã‚’é¸æŠ",
            valid_metric_options,
            key="metric_select"
        )

        chart_data = analysis_df[['response_time', metric_option, 'æ­£ç¢ºæ€§']].dropna() # NaNã‚’é™¤å¤–
        if not chart_data.empty:
             st.scatter_chart(
                chart_data,
                x='response_time',
                y=metric_option,
                color='æ­£ç¢ºæ€§',
            )
        else:
            st.info(f"é¸æŠã•ã‚ŒãŸæŒ‡æ¨™ ({metric_option}) ã¨å¿œç­”æ™‚é–“ã®æœ‰åŠ¹ãªãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")

    else:
        st.info("å¿œç­”æ™‚é–“ã¨æ¯”è¼ƒã§ãã‚‹æŒ‡æ¨™ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")


    # å…¨ä½“ã®è©•ä¾¡æŒ‡æ¨™ã®çµ±è¨ˆ
    st.write("##### è©•ä¾¡æŒ‡æ¨™ã®çµ±è¨ˆ")
    stats_cols = ['response_time', 'bleu_score', 'similarity_score', 'word_count', 'relevance_score']
    valid_stats_cols = [c for c in stats_cols if c in analysis_df.columns and analysis_df[c].notna().any()]
    if valid_stats_cols:
        metrics_stats = analysis_df[valid_stats_cols].describe()
        st.dataframe(metrics_stats)
    else:
        st.info("çµ±è¨ˆæƒ…å ±ã‚’è¨ˆç®—ã§ãã‚‹è©•ä¾¡æŒ‡æ¨™ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")

    # æ­£ç¢ºæ€§ãƒ¬ãƒ™ãƒ«åˆ¥ã®å¹³å‡ã‚¹ã‚³ã‚¢
    st.write("##### æ­£ç¢ºæ€§ãƒ¬ãƒ™ãƒ«åˆ¥ã®å¹³å‡ã‚¹ã‚³ã‚¢")
    if valid_stats_cols and 'æ­£ç¢ºæ€§' in analysis_df.columns:
        try:
            accuracy_groups = analysis_df.groupby('æ­£ç¢ºæ€§')[valid_stats_cols].mean()
            st.dataframe(accuracy_groups)
        except Exception as e:
            st.warning(f"æ­£ç¢ºæ€§åˆ¥ã‚¹ã‚³ã‚¢ã®é›†è¨ˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
    else:
         st.info("æ­£ç¢ºæ€§ãƒ¬ãƒ™ãƒ«åˆ¥ã®å¹³å‡ã‚¹ã‚³ã‚¢ã‚’è¨ˆç®—ã§ãã‚‹ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")


    # ã‚«ã‚¹ã‚¿ãƒ è©•ä¾¡æŒ‡æ¨™ï¼šåŠ¹ç‡æ€§ã‚¹ã‚³ã‚¢
    st.write("##### åŠ¹ç‡æ€§ã‚¹ã‚³ã‚¢ (æ­£ç¢ºæ€§ / (å¿œç­”æ™‚é–“ + 0.1))")
    if 'response_time' in analysis_df.columns and analysis_df['response_time'].notna().any():
        # ã‚¼ãƒ­é™¤ç®—ã‚’é¿ã‘ã‚‹ãŸã‚ã«0.1ã‚’è¿½åŠ 
        analysis_df['efficiency_score'] = analysis_df['is_correct'] / (analysis_df['response_time'].fillna(0) + 0.1)
        # IDã‚«ãƒ©ãƒ ãŒå­˜åœ¨ã™ã‚‹ã‹ç¢ºèª
        if 'id' in analysis_df.columns:
            # ä¸Šä½10ä»¶ã‚’è¡¨ç¤º
            top_efficiency = analysis_df.sort_values('efficiency_score', ascending=False).head(10)
            # id ã‚’ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã«ã™ã‚‹å‰ã«å­˜åœ¨ç¢ºèª
            if not top_efficiency.empty:
                st.bar_chart(top_efficiency.set_index('id')['efficiency_score'])
            else:
                st.info("åŠ¹ç‡æ€§ã‚¹ã‚³ã‚¢ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
        else:
            # IDãŒãªã„å ´åˆã¯å˜ç´”ã«ã‚¹ã‚³ã‚¢ã‚’è¡¨ç¤º
             st.bar_chart(analysis_df.sort_values('efficiency_score', ascending=False).head(10)['efficiency_score'])

    else:
        st.info("åŠ¹ç‡æ€§ã‚¹ã‚³ã‚¢ã‚’è¨ˆç®—ã™ã‚‹ãŸã‚ã®å¿œç­”æ™‚é–“ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")


# --- ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ç®¡ç†ãƒšãƒ¼ã‚¸ã®UI ---
def display_data_page():
    """ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ç®¡ç†ãƒšãƒ¼ã‚¸ã®UIã‚’è¡¨ç¤ºã™ã‚‹"""
    st.subheader("ã‚µãƒ³ãƒ—ãƒ«è©•ä¾¡ãƒ‡ãƒ¼ã‚¿ã®ç®¡ç†")
    count = get_db_count()
    st.write(f"ç¾åœ¨ã®ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ã¯ {count} ä»¶ã®ãƒ¬ã‚³ãƒ¼ãƒ‰ãŒã‚ã‚Šã¾ã™ã€‚")

    col1, col2 = st.columns(2)
    with col1:
        if st.button("ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’è¿½åŠ ", key="create_samples"):
            create_sample_evaluation_data()
            st.rerun() # ä»¶æ•°è¡¨ç¤ºã‚’æ›´æ–°

    with col2:
        # ç¢ºèªã‚¹ãƒ†ãƒƒãƒ—ä»˜ãã®ã‚¯ãƒªã‚¢ãƒœã‚¿ãƒ³
        if st.button("ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’ã‚¯ãƒªã‚¢", key="clear_db_button"):
            if clear_db(): # clear_dbå†…ã§ç¢ºèªã¨å®Ÿè¡Œã‚’è¡Œã†
                st.rerun() # ã‚¯ãƒªã‚¢å¾Œã«ä»¶æ•°è¡¨ç¤ºã‚’æ›´æ–°

    # è©•ä¾¡æŒ‡æ¨™ã«é–¢ã™ã‚‹è§£èª¬
    st.subheader("è©•ä¾¡æŒ‡æ¨™ã®èª¬æ˜")
    metrics_info = get_metrics_descriptions()
    for metric, description in metrics_info.items():
        with st.expander(f"{metric}"):
            st.write(description)

# --- ãƒ¬ãƒãƒ¼ãƒˆãƒšãƒ¼ã‚¸ã®UI ---
def display_report_page():
    """ãƒ¬ãƒãƒ¼ãƒˆãƒšãƒ¼ã‚¸ã®UIã‚’è¡¨ç¤ºã™ã‚‹"""
    st.subheader("ğŸ“„ ãƒ¬ãƒãƒ¼ãƒˆ")

    st.markdown("""
    ã“ã®ãƒšãƒ¼ã‚¸ã§ã¯ã€ã€AIã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°å®Ÿè·µè¬›åº§2025ã€‘ç¬¬1å›ã®å®¿é¡Œï¼ˆæ¼”ç¿’èª²é¡Œï¼‰ã®å®Ÿæ–½å†…å®¹ã‚’è¨˜è¿°ã—ã¦ã„ã¾ã™ã€‚

    ### ğŸ™‹
    Omnicampus ã‚¢ã‚«ã‚¦ãƒ³ãƒˆåï¼štaiga10969

    åå‰ï¼šå¢—ç”°å¤§æ²³

    ### ğŸ“Œ å®Ÿæ–½å†…å®¹<æ¦‚è¦>
    #### 1. UIã®æ”¹è‰¯
    - ãƒšãƒ¼ã‚¸ã®ã‚¿ã‚¤ãƒˆãƒ«è¡¨ç¤ºéƒ¨åˆ†ã«iconï¼ˆã‚¤ãƒ©ã‚¹ãƒˆï¼‰ã‚’è¿½åŠ ã€‚
    - ã‚¿ã‚¤ãƒˆãƒ«ã¨æ°åãªã©ã®æ–‡å­—ã‚‚å«ã‚ã¦1ã¤ã®ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«`ai-engineering_chatbot_icon.png`ã¨ã—ã¦ä½œæˆã—ã¦èª­ã¿è¾¼ã¿ãƒ»è¡¨ç¤ºã€‚
    #### 2. ãƒ¢ãƒ‡ãƒ«é¸æŠã®æ”¹è‰¯
    - ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆã«ä½¿ç”¨ã™ã‚‹gemmaãƒ¢ãƒ‡ãƒ«ã‚’é¸æŠã§ãã‚‹ã‚ˆã†ã«æ”¹è‰¯ã€‚
    - gemmaã®ä¸­ã«ã¯ã€æ—¥æœ¬èªãƒ†ã‚­ã‚¹ãƒˆå‘ã‘ã«å¾®èª¿æ•´ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã‚‚å…¬é–‹ã€‚
    - ã“ã‚Œã‚‰ã®è¤‡æ•°ã®ãƒ¢ãƒ‡ãƒ«ã®ä¸­ã‹ã‚‰ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒä½¿ç”¨ã—ãŸã„ãƒ¢ãƒ‡ãƒ«ã‚’é¸æŠã§ãã‚‹ã‚ˆã†ã«æ”¹è‰¯ã€‚
    #### 3. ãƒ¬ãƒãƒ¼ãƒˆãƒšãƒ¼ã‚¸ã®è¿½åŠ 
    - æœ¬æ¼”ç¿’ã®ãƒ¬ãƒãƒ¼ãƒˆãƒšãƒ¼ã‚¸ã‚’ä½œæˆãƒ»è¿½åŠ ã€‚
    - ã‚¢ãƒ—ãƒªä¸Šã§ã€ãƒšãƒ¼ã‚¸é¸æŠã§ãƒ¬ãƒãƒ¼ãƒˆãƒšãƒ¼ã‚¸ã‚’é¸æŠã™ã‚‹ã“ã¨ã§UIä¸Šã«ãƒ¬ãƒãƒ¼ãƒˆã‚’è¡¨ç¤ºã•ã›ã‚‹ã‚ˆã†ã«æ”¹è‰¯ã€‚

    ### âš™ï¸ å®Ÿè£…æ–¹æ³•
    #### 1. UIã®æ”¹è‰¯
    `app.py`ã«ç”»åƒã‚’è¡¨ç¤ºã•ã›ã‚‹ãƒ—ãƒ­ã‚°ãƒ©ãƒ ã‚’è¿½åŠ """)
    with st.expander("ãƒ—ãƒ­ã‚°ãƒ©ãƒ ã‚’è¦‹ã‚‹"):
        st.code("""            
                   - # --- Streamlit ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ ---
                   + st.image("ai-engineering_chatbot_icon.png", width=1000)
                   - st.title("ğŸ¤– Gemma 2 Chatbot with Feedback")
                   - st.write("Gemmaãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã—ãŸãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆã§ã™ã€‚å›ç­”ã«å¯¾ã—ã¦ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’è¡Œãˆã¾ã™ã€‚")
                   - st.markdown("---")
                """, language="python")
    st.markdown("""
    #### 2. ãƒ¢ãƒ‡ãƒ«é¸æŠã®æ”¹è‰¯
    app.pyã®ã‚µã‚¤ãƒ‰ãƒãƒ¼è¨­å®šéƒ¨åˆ†ã«ãƒ¢ãƒ‡ãƒ«é¸æŠã®ãƒ—ãƒ­ã‚°ãƒ©ãƒ ã‚’è¿½åŠ 


    æœ€åˆã«ãƒ¢ãƒ‡ãƒ«ãŒé¸æŠã•ã‚Œã¦ã„ã‚‹çŠ¶æ…‹ã ã¨ã€appã‚¢ã‚¯ã‚»ã‚¹æ™‚ã«ãƒ¢ãƒ‡ãƒ«ã®èª­ã¿è¾¼ã¿ãŒå§‹ã¾ã£ã¦ã—ã¾ã†ãŸã‚ã€åˆã‚ã¯ãƒ¢ãƒ‡ãƒ«ã‚’é¸æŠã—ã¦ä¸‹ã•ã„ã‚’é¸æŠã€‚""")
    with st.expander("ãƒ—ãƒ­ã‚°ãƒ©ãƒ ã‚’è¦‹ã‚‹ (ãƒ¢ãƒ‡ãƒ«é¸æŠéƒ¨åˆ†)"):
        st.code("""  
                    - # --- ã‚µã‚¤ãƒ‰ãƒãƒ¼ ---
                    - st.sidebar.title("ãƒŠãƒ“ã‚²ãƒ¼ã‚·ãƒ§ãƒ³")
                    - # ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã‚’ä½¿ç”¨ã—ã¦é¸æŠãƒšãƒ¼ã‚¸ã‚’ä¿æŒ
                    - if 'page' not in st.session_state:
                    -     st.session_state.page = "ãƒãƒ£ãƒƒãƒˆ" # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒšãƒ¼ã‚¸
                    - 
                    - 
                    + ## ãƒ¢ãƒ‡ãƒ«å€™è£œ
                    + model_options = [
                    +     "ãƒ¢ãƒ‡ãƒ«ã‚’é¸æŠã—ã¦ãã ã•ã„",
                    +     "google/gemma-2b", 
                    +     "google/gemma-2-2b-jpn-it",
                    + ]
                    + 
                    + ## ãƒ¢ãƒ‡ãƒ«é¸æŠï¼ˆã‚»ãƒƒã‚·ãƒ§ãƒ³ã«ä¿æŒï¼‰
                    + #if "selected_model" not in st.session_state:
                    + #    st.session_state.selected_model = MODEL_NAME
                    + 
                    + # åˆæœŸé¸æŠã‚’ã€Œãƒ¢ãƒ‡ãƒ«ã‚’é¸æŠã—ã¦ãã ã•ã„ã€ã«ã™ã‚‹
                    + if "selected_model" not in st.session_state:
                    +     st.session_state.selected_model = "ãƒ¢ãƒ‡ãƒ«ã‚’é¸æŠã—ã¦ãã ã•ã„"
                    + 
                    + selected_model = st.sidebar.selectbox(
                    +     "ä½¿ç”¨ã™ã‚‹ãƒ¢ãƒ‡ãƒ«ã‚’é¸æŠ",
                    +     model_options,
                    +     index=model_options.index(st.session_state.selected_model) if st.session_state.selected_model in model_options else 0,
                    +     on_change=lambda: st.session_state.update(selected_model=st.session_state.selected_model_selector),
                    +     key="selected_model_selector"
                    + )
                    + 
                    + page = st.sidebar.radio(
                    +     "ãƒšãƒ¼ã‚¸é¸æŠ",
                    +     ["ãƒãƒ£ãƒƒãƒˆ", "å±¥æ­´é–²è¦§", "ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ç®¡ç†", "ãƒ¬ãƒãƒ¼ãƒˆ"],
                    +     key="page_selector",
                    +     index=["ãƒãƒ£ãƒƒãƒˆ", "å±¥æ­´é–²è¦§", "ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ç®¡ç†", "ãƒ¬ãƒãƒ¼ãƒˆ"].index(st.session_state.page), # ç¾åœ¨ã®ãƒšãƒ¼ã‚¸ã‚’é¸æŠçŠ¶æ…‹ã«ã™ã‚‹
                    +     on_change=lambda: setattr(st.session_state, 'page', st.session_state.page_selector) # é¸æŠå¤‰æ›´æ™‚ã«çŠ¶æ…‹ã‚’æ›´æ–°
                    + )
                """, language="python")
    st.markdown("""
    ã•ã‚‰ã«ã€`app.py`ä¸Šã§ãƒ¢ãƒ‡ãƒ«ã‚’loadã™ã‚‹éƒ¨åˆ†ã‚’å¼•æ•°ã§ãƒ¢ãƒ‡ãƒ«åã‚’å—ã‘å–ã£ã¦å®Ÿè¡Œã§ãã‚‹ã‚ˆã†ã«å¤‰æ›´ã™ã‚‹ã€‚""")
    with st.expander("ãƒ—ãƒ­ã‚°ãƒ©ãƒ ã‚’è¦‹ã‚‹ (ãƒ¢ãƒ‡ãƒ«ãƒ­ãƒ¼ãƒ‰éƒ¨åˆ†)"):
        st.code("""  
                    - #LLMãƒ¢ãƒ‡ãƒ«ã®ãƒ­ãƒ¼ãƒ‰ï¼ˆã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’åˆ©ç”¨ï¼‰
                    - #ãƒ¢ãƒ‡ãƒ«ã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã—ã¦å†åˆ©ç”¨
                    - @st.cache_resource
                    - def load_model():
                    -     #LLMãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰ã™ã‚‹
                    -     try:
                    -         device = "cuda" if torch.cuda.is_available() else "cpu"
                    -         st.info(f"Using device: {device}") # ä½¿ç”¨ãƒ‡ãƒã‚¤ã‚¹ã‚’è¡¨ç¤º
                    -         pipe = pipeline(
                    -             "text-generation",
                    -             model=MODEL_NAME,
                    -             model_kwargs={"torch_dtype": torch.bfloat16},
                    -             device=device
                    -         )
                    -         st.success(f"ãƒ¢ãƒ‡ãƒ« '{MODEL_NAME}' ã®èª­ã¿è¾¼ã¿ã«æˆåŠŸã—ã¾ã—ãŸã€‚")
                    -         return pipe
                    -     except Exception as e:
                    -         st.error(f"ãƒ¢ãƒ‡ãƒ« '{MODEL_NAME}' ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
                    -         st.error("GPUãƒ¡ãƒ¢ãƒªä¸è¶³ã®å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚ä¸è¦ãªãƒ—ãƒ­ã‚»ã‚¹ã‚’çµ‚äº†ã™ã‚‹ã‹ã€ã‚ˆã‚Šå°ã•ã„ãƒ¢ãƒ‡ãƒ«ã®ä½¿ç”¨ã‚’æ¤œè¨ã—ã¦ãã ã•ã„ã€‚")
                    -         return None
                    - pipe = load_model()

                    + ## ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿
                    + # LLMãƒ¢ãƒ‡ãƒ«ã®ãƒ­ãƒ¼ãƒ‰ï¼ˆã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’åˆ©ç”¨ï¼‰
                    + # ãƒ¢ãƒ‡ãƒ«ã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã—ã¦å†åˆ©ç”¨
                    + @st.cache_resource
                    + def load_model(model_name):
                    +     #LLMãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰ã™ã‚‹
                    +     try:
                    +         device = "cuda" if torch.cuda.is_available() else "cpu"
                    +         st.info(f"Using device: {device}") # ä½¿ç”¨ãƒ‡ãƒã‚¤ã‚¹ã‚’è¡¨ç¤º
                    +         pipe = pipeline(
                    +             "text-generation",
                    +             model=model_name,
                    +             model_kwargs={"torch_dtype": torch.bfloat16},
                    +             device=device
                    +         )
                    +         st.success(f"ãƒ¢ãƒ‡ãƒ« '{model_name}' ã®èª­ã¿è¾¼ã¿ã«æˆåŠŸã—ã¾ã—ãŸã€‚")
                    +         return pipe
                    +     except Exception as e:
                    +         st.error(f"ãƒ¢ãƒ‡ãƒ« '{model_name}' ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
                    +         st.error("GPUãƒ¡ãƒ¢ãƒªä¸è¶³ã®å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚ä¸è¦ãªãƒ—ãƒ­ã‚»ã‚¹ã‚’çµ‚äº†ã™ã‚‹ã‹ã€ã‚ˆã‚Šå°ã•ã„ãƒ¢ãƒ‡ãƒ«ã®ä½¿ç”¨ã‚’æ¤œè¨ã—ã¦ãã ã•ã„ã€‚")
                    +         return None
                    + pipe = load_model(st.session_state.selected_model)
                """, language="python")
    st.markdown("""
    ä»Šå›é¸æŠå¯èƒ½ã«ã—ãŸãƒ¢ãƒ‡ãƒ«ã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ¢ãƒ‡ãƒ«ã«1ã¤è¿½åŠ ã—ãŸã€‚
    - ãƒ¢ãƒ‡ãƒ«: `gemma-2b` / `gemma-2-2b-jpn-it`

    #### 3. ãƒ¬ãƒãƒ¼ãƒˆãƒšãƒ¼ã‚¸ã®è¿½åŠ 
    `app.py`ã®ã‚µã‚¤ãƒ‰ãƒãƒ¼è¨­å®šéƒ¨åˆ†ã«ãƒ¢ãƒ‡ãƒ«é¸æŠã®ãƒ—ãƒ­ã‚°ãƒ©ãƒ ã‚’è¿½åŠ """)
    with st.expander("ãƒ—ãƒ­ã‚°ãƒ©ãƒ ã‚’è¦‹ã‚‹"):
        st.code("""            
                    - # --- ãƒ¡ã‚¤ãƒ³ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ ---
                    - if st.session_state.page == "ãƒãƒ£ãƒƒãƒˆ":
                    -     if pipe:
                    -         ui.display_chat_page(pipe)
                    -     else:
                    -         st.error("ãƒãƒ£ãƒƒãƒˆæ©Ÿèƒ½ã‚’åˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚ãƒ¢ãƒ‡ãƒ«ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
                    - elif st.session_state.page == "å±¥æ­´é–²è¦§":
                    -     ui.display_history_page()
                    - elif st.session_state.page == "ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ç®¡ç†":
                    -     ui.display_data_page()
                    + elif st.session_state.page == "ãƒ¬ãƒãƒ¼ãƒˆ":
                    +     ui.display_report_page()
                """, language="python")
    st.markdown("""
    ãã®ä»–ã€ãƒ¬ãƒãƒ¼ãƒˆã‚’è¡¨ç¤ºã•ã›ã‚‹éƒ¨åˆ†ã¯`ui.py`ã«`display_report_page()`ã‚’å®šç¾©ã—ã¦ã„ã‚‹ã€‚

    ### ğŸ¤— ãƒ¢ãƒ‡ãƒ«ã®å¤‰æ›´ã«ä¼´ã†å‡ºåŠ›çµæœã®å¤‰åŒ–
    è³ªå•æ–‡ï¼šã€Œæ¡ƒå¤ªéƒã«ã¤ã„ã¦ãŠã—ãˆã¦ãã ã•ã„ã€
    - `gemma-2b`
    - `gemma-2-2b-jpn-it`
    ```
    #æ¡ƒå¤ªéƒã«ã¤ã„ã¦
    æ¡ƒå¤ªéƒã¯ã€æ—¥æœ¬ã®æ°‘é–“ä¼æ‰¿ã§ã‚ã‚Šã€å­ä¾›ãŸã¡ã«è¦ªã—ã¿ã‚„ã™ã„ç‰©èªã§ã™ã€‚
    ##ã‚ã‚‰ã™ã˜
    - æ¡ƒã®æ¨¹ã¨ã€æ¡ƒå¤ªéƒã®èª•ç”Ÿ: æ¡ƒå¤ªéƒã¯ã€ã‚ã‚‹æ‘ã®ç‰©èªã«ç™»å ´ã™ã‚‹ä¸»äººå…¬ã§ã™ã€‚
    - æ‚ªé¬¼ã®è¥²æ’ƒ: æ‘ã‚’è¥²ã†æ‚ªé¬¼ã¯ã€æ¡ƒã‚’å¥ªã„ã€äººã€…ã‚’è‹¦ã—ã‚ã¾ã™ã€‚
    - æ¡ƒå¤ªéƒã®æ´»èº: æ¡ƒå¤ªéƒã¯ã€æ‚ªé¬¼ã¨æˆ¦ã„ã€æ¡ƒã‚’å¥ªã„ã€æ‘ã‚’æ•‘ã„ã¾ã™ã€‚
    - å‹åˆ©ã¨ä¼èª¬: æ¡ƒå¤ªéƒã®æ´»èºã¯ã€æ‘ã®äººã€…ã«å¸Œæœ›ã‚’ä¸ãˆã€ãã®ä¼èª¬ã¯ä¸–ä»£ã‚’è¶…ãˆã¦èªã‚Šç¶™ãŒã‚Œã¦ã„ã¾ã™ã€‚
    ##ç‰¹å¾´
    - å­ä¾›å‘ã‘: æ¡ƒå¤ªéƒã¯ã€å­ä¾›ãŸã¡ã«è¦ªã—ã¿ã‚„ã™ã„ã€å˜ç´”æ˜å¿«ãªç‰©èªã§ã™ã€‚
    - å‹‡æ•¢ã•ã€æ­£ç¾©æ„Ÿ: æ¡ƒå¤ªéƒã¯ã€å‹‡æ•¢ã§æ­£ç¾©æ„Ÿã‚ãµã‚Œã‚‹ä¸»äººå…¬ã§ã™ã€‚
    - ä¼çµ±çš„ãªæ—¥æœ¬ã®ç‰©èª: æ¡ƒå¤ªéƒã¯ã€æ—¥æœ¬ã®ä¼çµ±çš„ãªç‰©èªã®ä¸€ä¾‹ã§ã™ã€‚
    - æ§˜ã€…ãªè§£é‡ˆ: æ¡ƒå¤ªéƒã¯ã€æ§˜ã€…ãªè§£é‡ˆã§è¡¨ç¾ã•ã‚Œã¦ãŠã‚Šã€ç¾ä»£ã«ãŠã„ã¦ã‚‚äººæ°—ãŒã‚ã‚Šã¾ã™ã€‚
    ##æ¡ƒå¤ªéƒã®æ–‡åŒ–çš„ãªå½±éŸ¿
    - çµµç”»ã€å½«åˆ»ã€æ–‡å­¦: æ¡ƒå¤ªéƒã¯ã€æ—¥æœ¬ã®ç¾è¡“ã‚„æ–‡å­¦ã«å¤§ããªå½±éŸ¿ã‚’ä¸ãˆã¾ã—ãŸã€‚
    - æ¼”åŠ‡ã€ã‚¢ãƒ‹ãƒ¡ã€æ¼«ç”»: æ¡ƒå¤ªéƒã¯ã€å¤šãã®æ¼”åŠ‡ã€ã‚¢ãƒ‹ãƒ¡ã€æ¼«ç”»ã§æã‹ã‚Œã€ç¾ä»£ã§ã‚‚åºƒãçŸ¥ã‚‰ã‚Œã¦ã„ã¾ã™ã€‚
    - ç¥­ã‚Š: æ¡ƒå¤ªéƒç¯€ã‚„ã€æ¡ƒå¤ªéƒç¥­ã‚Šãªã©ã€æ§˜ã€…ãªç¥­ã‚ŠãŒé–‹å‚¬ã•ã‚Œã€æ¡ƒå¤ªéƒã®æ–‡åŒ–ãŒä¼ã‚ã‚‹æ©Ÿä¼šãŒã‚ã‚Šã¾ã™ã€‚
    ```

    ---
    Omnicampus ã‚¢ã‚«ã‚¦ãƒ³ãƒˆåï¼štaiga10969

    åå‰ï¼šå¢—ç”°å¤§æ²³
    """)